#
# dd-data-vault configuration file
#
server:
  applicationContextPath: /
  adminContextPath: /
  applicationConnectors:
    - type: http
      port: 20365
  adminConnectors:
    - type: http
      port: 20366
  requestLog:
    appenders:
      - type: file
        archive: false
        timeZone: system
        currentLogFilename: /var/opt/dans.knaw.nl/log/dd-data-vault/request.log

database:
  driverClass: org.postgresql.Driver
  url: jdbc:postgresql://localhost:5432/dd_data_vault
  user: changeme
  password: changeme
  logValidationErrors: true
  properties:
    hibernate.dialect: 'org.hibernate.dialect.PostgreSQL95Dialect'
    hibernate.hbm2ddl.auto: update

executorService:
  nameFormat: "create-or-update-object-worker-%d"
  maxQueueSize: 5000
  # Number of threads will be increased when maxQueueSize is exceeded.
  minThreads: 2
  # No more than maxThreads will be created though
  maxThreads: 5
  # Threads will die after 60 seconds of idleness
  keepAliveTime: 60 seconds

dataVault:
  #
  # Regular expression that object identifiers must match.
  #
  validObjectIdentifierPattern: "urn:nbn:nl:ui:13-.*"

  #
  # Settings for the ingest area
  #
  ingest:
    # TODO: rename dir data-vault to dd-data-vault
    #
    # Object import directories must be located under the inbox directory, possibly in a batch subdirectory.
    #
    inbox: /var/opt/dans.knaw.nl/tmp/data-vault/inbox
    #
    # Object import directories that have been processed are moved to the outbox directory, under the same relative path as in the inbox, 
    # with an additional 'processed' or 'failed' subdirectory.
    # 
    # For example, if an object import directory is located at /var/opt/dans.knaw.nl/tmp/data-vault/inbox/batch-1, then after processing it is moved to
    # /var/opt/dans.knaw.nl/tmp/data-vault/outbox/batch-1/processed or /var/opt/dans.knaw.nl/tmp/data-vault/outbox/batch-1/failed.
    #
    outbox: /var/opt/dans.knaw.nl/tmp/data-vault/outbox

  #
  #
  #
  ocflRepository:
    workDir: /data/vault/tmp

  #
  # Settings for the layer store in which the data vault stores its data.
  #
  layerStore:
    #
    # Directory containing staged layers. A new layer is first staged under this directory. When it is full enough, it is then
    # packaged into an archive file and stored under the archiveRoot. It is up to the client to decide when a layer is full enough.
    #
    stagingRoot: /data/vault/staging

    #
    # Class that creates and manages the archive files. Several implementations are available. Only one of them can be active at a time.
    #
    archiveProvider:
      type: TAR
      archiveRoot: /data/vault/archive

    #   type: ZIP
    #   archiveRoot: /var/opt/dans.knaw.nl/tmp/dd-data-vault/archive

    #   type: DMFTAR
    #   dmfTarExecutable: /usr/local/bin/dmftar # path to the dmftar executable
    #   sshExecutable: /usr/bin/ssh # path to the ssh executable
    #   host: <host where DMF runs>
    #   user: <user to log in to DMF host>
    #   archiveRoot: <directory on DMF host where the archive files are stored>

#
# See https://www.dropwizard.io/en/latest/manual/configuration.html#logging
#
logging:
  level: INFO
  appenders:
    - type: file
      archive: false
      timeZone: system
      currentLogFilename: /var/opt/dans.knaw.nl/log/dd-data-vault/dd-data-vault.log
      logFormat: "%-5p [%d{ISO8601}] %c{0}: %m%n%dwREx"
    - type: console
      # Used in combination with journald, which already adds the timestamp
      logFormat: "%-5p %c{0}: %m%n%dwREx"
  loggers:
    'org.hibernate.engine.internal.StatisticalLoggingSessionEventListener': 'OFF'
