
server:
  applicationContextPath: /
  adminContextPath: /
  applicationConnectors:
    - type: http
      port: 20365
  adminConnectors:
    - type: http
      port: 20366

database:
  driverClass: org.hsqldb.jdbcDriver
  url: jdbc:hsqldb:hsql://localhost:9004/dd-data-vault
  logValidationErrors: true
  # See: https://stackoverflow.com/questions/10684244/dbcp-validationquery-for-different-databases
  validationQuery: SELECT * FROM INFORMATION_SCHEMA.SYSTEM_TABLES
  properties:
    hibernate.dialect: 'org.hibernate.dialect.HSQLDialect'
    hibernate.hbm2ddl.auto: update

dataVault:
  #
  # Regular expression that object identifiers must match.
  #
  validObjectIdentifierPattern: "urn:nbn:nl:ui:13-.*"

  #
  # Settings for the ingest area
  #
  ingest:
    #
    # Object import directories must be located under the inbox directory, possibly in a batch subdirectory.
    #
    inbox: data/ingest/inbox
    #
    # Object import directories that have been processed are moved to the outbox directory, under the same relative path as in the inbox, 
    # with an additional 'processed' or 'failed' subdirectory.
    # 
    # For example, if an object import directory is located at /var/opt/dans.knaw.nl/tmp/data-vault/inbox/batch-1, then after processing it is moved to
    # /var/opt/dans.knaw.nl/tmp/data-vault/outbox/batch-1/processed or /var/opt/dans.knaw.nl/tmp/data-vault/outbox/batch-1/failed.
    #
    outbox: data/ingest/outbox


  #
  #
  #
  ocflRepository:
    workDir: data/ocfl-work
    rootExtensionsSourcePath: src/main/assembly/dist/cfg/ocfl-root-extensions

  #
  # Default version information to be used when no version information is provided when adding an object version. Currently, there is no way to
  # provide version information when adding an object version, so this is the only way to set user information.
  #
  defaultVersionInfo:
    username: changeme
    email: changeme@example.com
    message: change me

  #
  # Settings for the layer store in which the data vault stores its data.
  #
  layerStore:
    #
    # Directory containing staged layers. A new layer is first staged under this directory. When it is full enough, it is then
    # packaged into an archive file and stored under the archiveRoot.
    #
    stagingRoot: data/vault/staging

    #
    # Directory containing archived layers.
    #
    archiveProvider:
      type: TAR
      archiveRoot: data/vault/archive

    #   type: ZIP
    #   archiveRoot: data/vault/archive

    #   type: DMFTAR
    #   dmfTarExecutable: /usr/local/bin/dmftar # path to the dmftar executable
    #   sshExecutable: /usr/bin/ssh # path to the ssh executable
    #   host: <host where DMF runs>
    #   user: <user to log in to DMF host>
    #   archiveRoot: <directory on DMF host where the archive files are stored>

    #
    # The service can do the following consistency checks on the layered store:
    #
    # - LAYER_IDS: check that the layer IDs found in the database are the same as the ones found on storage
    # - LISTING_RECORDS: check that the listing records found in the database correspond one-to-one with entries in a given layer
    #
    # These checks can be requested via the /consistency-checks endpoint. The LISTING_RECORDS check will also be performed automatically when a layer is archived.
    #
    consistencyCheckExecutor:
      # How often to poll for scheduled consistency checks. The oldest unfinished check will be executed.
      pollingInterval: 10 seconds

executorService:
  nameFormat: "create-or-update-object-worker-%d"
  maxQueueSize: 5000
  # Number of threads will be increased when maxQueueSize is exceeded.
  minThreads: 2
  # No more than maxThreads will be created though
  maxThreads: 5
  # Threads will die after 60 seconds of idleness
  keepAliveTime: 60 seconds



#
# See https://www.dropwizard.io/en/latest/manual/configuration.html#logging
#
logging:
  level: INFO
  appenders:
    - type: console
      logFormat: "%-5p [%d{ISO8601}] [%t] %c: %m%n%rEx"

    - type: file
      archive: false
      currentLogFilename: data/dd-data-vault.log
  loggers:
    'nl.knaw.dans': 'DEBUG'
    'org.hibernate.engine.internal.StatisticalLoggingSessionEventListener': 'OFF'