#
# dd-data-vault configuration file
#
server:
  applicationContextPath: /
  adminContextPath: /
  applicationConnectors:
    - type: http
      port: 20365
  adminConnectors:
    - type: http
      port: 20366
  requestLog:
    appenders:
      - type: file
        archive: false
        timeZone: system
        currentLogFilename: data/request.log

database:
  driverClass: org.postgresql.Driver
  url: jdbc:postgresql://dev.transfer.dans-data.nl:5432/dd_data_vault_local_test
  user: dd_data_vault_local_test
  password: dd_data_vault_local_test
  logValidationErrors: true
  properties:
    hibernate.dialect: 'org.hibernate.dialect.PostgreSQL95Dialect'
    hibernate.hbm2ddl.auto: update

#database:
#  driverClass: org.hsqldb.jdbcDriver
#  url: jdbc:hsqldb:hsql://localhost:9004/dd-data-vault
#  logValidationErrors: true
#  # See: https://stackoverflow.com/questions/10684244/dbcp-validationquery-for-different-databases
#  validationQuery: SELECT * FROM INFORMATION_SCHEMA.SYSTEM_TABLES
#  properties:
#    hibernate.dialect: 'org.hibernate.dialect.HSQLDialect'
#    hibernate.hbm2ddl.auto: update


executorService:
  nameFormat: "create-or-update-object-worker-%d"
  maxQueueSize: 5000
  # Number of threads will be increased when maxQueueSize is exceeded.
  minThreads: 2
  # No more than maxThreads will be created though
  maxThreads: 5
  # Threads will die after 60 seconds of idleness
  keepAliveTime: 60 seconds

dataVault:
  #
  # Regular expression that object identifiers must match.
  #
  validObjectIdentifierPattern: "urn:nbn:nl:ui:13-.*"

  #
  # Settings for the ingest area
  #
  ingest:
    #
    # Object import directories must be located under the inbox directory, possibly in a batch subdirectory.
    #
    inbox: data/ingest/inbox
    #
    # Object import directories that have been processed are moved to the outbox directory, under the same relative path as in the inbox, 
    # with an additional 'processed' or 'failed' subdirectory.
    # 
    # For example, if an object import directory is located at /var/opt/dans.knaw.nl/tmp/data-vault/inbox/batch-1, then after processing it is moved to
    # /var/opt/dans.knaw.nl/tmp/data-vault/outbox/batch-1/processed or /var/opt/dans.knaw.nl/tmp/data-vault/outbox/batch-1/failed.
    #
    outbox: data/ingest/outbox
    # Set to true if you want processed object import directories to be deleted after processing.
    # In a debugging setting this is probably not what you want.
    autoclean: false

  #
  #
  #
  ocflRepository:
    workDir: data/ocfl-work
    rootExtensionsSourcePath: etc/ocfl-root-extensions
    rootDocsSourcePath: etc/ocfl-root-docs
#  Uncomment if you want to test with 'dataset-version' as a required property.
#    rootExtensionsInit:
#      - file: property-registry/config.json
#        jsonPath: $.propertyRegistry.dataset-version.required
#        value: true

  #
  # Settings for the layer store in which the data vault stores its data.
  #
  layerStore:
    #
    # Directory containing staged layers. A new layer is first staged under this directory. When it is full enough, it is then
    # packaged into an archive file and stored under the archiveRoot.
    #
    stagingRoot: data/vault/staging

    #
    # Directory containing archived layers.
    #
    archiveProvider:
      type: TAR
      archiveRoot: data/vault/archive

    #
    # The threshold at which a layer is archived. Note that this means the layer can be substantially larger than the threshold, namely when a large batch is
    # offered when the layer is nearly full. This is not a problem because the threshold is intended to ensure a minimum size of the archive file rather than
    # a maximum size.
    #
    layerArchivingThreshold: 1G

    #   type: ZIP
    #   archiveRoot: data/vault/archive

    #   type: DMFTAR
    #   dmfTarExecutable: /usr/local/bin/dmftar # path to the dmftar executable
    #   sshExecutable: /usr/bin/ssh # path to the ssh executable
    #   host: <host where DMF runs>
    #   user: <user to log in to DMF host>
    #   archiveRoot: <directory on DMF host where the archive files are stored>

    #
    # The service can do the following consistency checks on the layered store:
    #
    # - LAYER_IDS: check that the layer IDs found in the database are the same as the ones found on storage
    # - LISTING_RECORDS: check that the listing records found in the database correspond one-to-one with entries in a given layer
    #
    # These checks can be requested via the /consistency-checks endpoint. The LISTING_RECORDS check will also be performed automatically when a layer is archived.
    #
    consistencyCheckExecutor:
      # How often to poll for scheduled consistency checks. The oldest unfinished check will be executed.
      pollingInterval: 10 seconds

    #
    # The consistency checks to perform on service startup.
    #
    initChecks:
      # Check that the layer IDs found in the database are the same as the ones found on storage. This may be slow if the layers are stored on a remote storage.
      layerIds: true
      # Check that the listing records for the top layer found in the database correspond one-to-one with entries in that layer.
      topLayerListingRecords: true


#
# See https://www.dropwizard.io/en/latest/manual/configuration.html#logging
#
logging:
  level: INFO
  appenders:
    - type: console
      logFormat: "%-5p [%d{ISO8601}] [%t] %c: %m%n%rEx"

    - type: file
      archive: false
      currentLogFilename: data/dd-data-vault.log
  loggers:
    'nl.knaw.dans': 'DEBUG'
    'org.hibernate.engine.internal.StatisticalLoggingSessionEventListener': 'OFF'